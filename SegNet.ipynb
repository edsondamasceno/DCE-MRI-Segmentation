{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SegNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiTmIrTts5Um"
      },
      "source": [
        "Link: https://www.kaggle.com/hashbanger/skin-lesion-segmentation-using-segnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUlcvudlnLO1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bIeQ_a2nY3E"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "# importing required modules \n",
        "from zipfile import ZipFile \n",
        "\n",
        "from skimage.io import imread,imshow\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Activation, Dense, BatchNormalization, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Input, Reshape\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import backend as K\n",
        "#from keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from warnings import filterwarnings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFXqRJ6WnY0R"
      },
      "source": [
        "IMG_WIDTH = 320\n",
        "IMG_HEIGHT = 160\n",
        "IMG_CHANNELS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GGrVJ3eoRiH"
      },
      "source": [
        "#Function for data visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XAmy30poLpF"
      },
      "source": [
        "def visualize(**images):\n",
        "    \"\"\"PLot images in one row.\"\"\"\n",
        "    n = len(images)\n",
        "    plt.figure()\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMrdbnBsoLi9"
      },
      "source": [
        "def visualize_01(**images):\n",
        "    \"\"\"PLot images in one row.\"\"\"\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TPLHx-4qOsZ"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdWwd9gQqH14"
      },
      "source": [
        "# specifying the zip file name\n",
        "TRAIN_Name='/content/drive/MyDrive/Mestrado/Segmentation/DCE-MRI-30-70/dce-mri_train.zip'\n",
        "TEST_Name ='/content/drive/MyDrive/Mestrado/Segmentation/DCE-MRI-30-70/dce-mri_test.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BrFhaiZqHu9"
      },
      "source": [
        "with ZipFile(TRAIN_Name, 'r') as zip: \n",
        "    # printing all the contents of the zip file       \n",
        "    # extracting all the files \n",
        "    print('Extracting all the train files now...') \n",
        "    zip.extractall(\"stage_train\") \n",
        "    print('Done!') \n",
        "    \n",
        "# opening the test zip file in READ mode \n",
        "with ZipFile(TEST_Name, 'r') as zip: \n",
        "    # printing all the contents of the zip file     \n",
        "    # extracting all the files \n",
        "    print('Extracting all the test files now...') \n",
        "    zip.extractall(\"stage_test\") \n",
        "    print('Done!') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlTkDOVjqHqn"
      },
      "source": [
        "TRAIN_PATH='/content/stage_train/dce-mri_train/'\n",
        "TEST_PATH='/content/stage_test/dce-mri_test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N1se6ZQqbsk"
      },
      "source": [
        "train_ids=next(os.walk(TRAIN_PATH))[1]\n",
        "test_ids=next(os.walk(TEST_PATH))[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnIUJrO5qbpH"
      },
      "source": [
        "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGbvUuV-qbjr"
      },
      "source": [
        "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQMEdZNRqbbv"
      },
      "source": [
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'Y_train shape: {Y_train.shape}')\n",
        "print(f'X_test shape: {X_test.shape}')\n",
        "print(f'Y_test shape: {Y_test.shape}')\n",
        "print(f'train_ids : {len(train_ids)}')\n",
        "print(f'test_ids : {len(test_ids)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngjgCR11qbTT"
      },
      "source": [
        "print('Resizing training images and masks')\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n",
        "    path = TRAIN_PATH + id_\n",
        "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]  \n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_train[n] = img  #Fill empty X_train with values from img\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "        mask_ = imread(path + '/masks/' + mask_file)\n",
        "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
        "                                      preserve_range=True), axis=-1)\n",
        "        mask = np.maximum(mask, mask_)  \n",
        "            \n",
        "    Y_train[n] = mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5bQmTAgqtbw"
      },
      "source": [
        "# test images\n",
        "sizes_test = []\n",
        "\n",
        "print('Resizing test images') \n",
        "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "    path = TEST_PATH + id_\n",
        "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "    sizes_test.append([img.shape[0], img.shape[1]])\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_test[n] = img\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "        mask_ = imread(path + '/masks/' + mask_file)\n",
        "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
        "                                      preserve_range=True), axis=-1)\n",
        "        mask = np.maximum(mask, mask_)\n",
        "\n",
        "    Y_test[n] = mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwkfG2cbnliG"
      },
      "source": [
        "# Jaccard index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug1G77VTnYw3"
      },
      "source": [
        "def iou(y_true, y_pred, smooth = 100):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return jac"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQk4Eqy7nvu7"
      },
      "source": [
        "# Dice coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GeBK_TbnYtP"
      },
      "source": [
        "def dice_coef(y_true, y_pred, smooth = 100):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt_-o6FHnzeL"
      },
      "source": [
        "# Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B4F20OSnYqG"
      },
      "source": [
        "def precision(y_true, y_pred):\n",
        "    '''Calculates the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    '''\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzglgBNnn4T5"
      },
      "source": [
        "# Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWo7uk4jnYlp"
      },
      "source": [
        "def recall(y_true, y_pred):\n",
        "    '''Calculates the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    '''\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm6_t1PIn_k5"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiEHsXJpnYgv"
      },
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    '''Calculates the mean accuracy rate across all predictions for binary\n",
        "    classification problems.\n",
        "    '''\n",
        "    return K.mean(K.equal(y_true, K.round(y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfMAJMcLrjJs"
      },
      "source": [
        "# Making a Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iMPa71UoEpe"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size = 0.10, random_state = 101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcZC_BOOrYgq"
      },
      "source": [
        "print(\"Length of the Training Set   : {}\".format(len(x_train)))\n",
        "print(\"Length of the Validation Set : {}\".format(len(x_val)))\n",
        "print(\"Length of the Test Set       : {}\".format(len(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4BUFskdpohp"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j3Mi4q5r1VE"
      },
      "source": [
        "def segnet(epochs_num,savename):\n",
        "\n",
        "    # Encoding layer\n",
        "    img_input = Input(shape= (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\n",
        "    x = BatchNormalization(name='bn1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='conv2')(x)\n",
        "    x = BatchNormalization(name='bn2')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    \n",
        "    x = Conv2D(128, (3, 3), padding='same', name='conv3')(x)\n",
        "    x = BatchNormalization(name='bn3')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='conv4')(x)\n",
        "    x = BatchNormalization(name='bn4')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='conv5')(x)\n",
        "    x = BatchNormalization(name='bn5')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='conv6')(x)\n",
        "    x = BatchNormalization(name='bn6')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='conv7')(x)\n",
        "    x = BatchNormalization(name='bn7')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='conv8')(x)\n",
        "    x = BatchNormalization(name='bn8')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='conv9')(x)\n",
        "    x = BatchNormalization(name='bn9')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='conv10')(x)\n",
        "    x = BatchNormalization(name='bn10')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    \n",
        "    x = Conv2D(512, (3, 3), padding='same', name='conv11')(x)\n",
        "    x = BatchNormalization(name='bn11')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='conv12')(x)\n",
        "    x = BatchNormalization(name='bn12')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='conv13')(x)\n",
        "    x = BatchNormalization(name='bn13')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "\n",
        "    x = Dense(1024, activation = 'relu', name='fc1')(x)\n",
        "    x = Dense(1024, activation = 'relu', name='fc2')(x)\n",
        "    # Decoding Layer \n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv1')(x)\n",
        "    x = BatchNormalization(name='bn14')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv2')(x)\n",
        "    x = BatchNormalization(name='bn15')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv3')(x)\n",
        "    x = BatchNormalization(name='bn16')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv4')(x)\n",
        "    x = BatchNormalization(name='bn17')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv5')(x)\n",
        "    x = BatchNormalization(name='bn18')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv6')(x)\n",
        "    x = BatchNormalization(name='bn19')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv7')(x)\n",
        "    x = BatchNormalization(name='bn20')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv8')(x)\n",
        "    x = BatchNormalization(name='bn21')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv9')(x)\n",
        "    x = BatchNormalization(name='bn22')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv10')(x)\n",
        "    x = BatchNormalization(name='bn23')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv11')(x)\n",
        "    x = BatchNormalization(name='bn24')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv12')(x)\n",
        "    x = BatchNormalization(name='bn25')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\n",
        "    x = BatchNormalization(name='bn26')(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    pred = Reshape((IMG_HEIGHT, IMG_WIDTH))(x)\n",
        "    \n",
        "    model = Model(inputs=img_input, outputs=pred)\n",
        "    \n",
        "    model.compile(optimizer= SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False), loss= [\"binary_crossentropy\"]\n",
        "                  , metrics=[iou, dice_coef, precision, recall, accuracy])\n",
        "    model.summary()\n",
        "    hist = model.fit(x_train, y_train, epochs= epochs_num, batch_size= 8, validation_data= (x_val, y_val), verbose=1)\n",
        "    \n",
        "    model.save(savename)\n",
        "    return model,hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNxJ5J9AwSSC"
      },
      "source": [
        "# Loading the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC2TuJDDwTDh"
      },
      "source": [
        "# Encoding layer\n",
        "img_input = Input(shape= (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "x = Conv2D(64, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\n",
        "x = BatchNormalization(name='bn1')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', name='conv2')(x)\n",
        "x = BatchNormalization(name='bn2')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), padding='same', name='conv3')(x)\n",
        "x = BatchNormalization(name='bn3')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(128, (3, 3), padding='same', name='conv4')(x)\n",
        "x = BatchNormalization(name='bn4')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), padding='same', name='conv5')(x)\n",
        "x = BatchNormalization(name='bn5')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(256, (3, 3), padding='same', name='conv6')(x)\n",
        "x = BatchNormalization(name='bn6')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(256, (3, 3), padding='same', name='conv7')(x)\n",
        "x = BatchNormalization(name='bn7')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "x = Conv2D(512, (3, 3), padding='same', name='conv8')(x)\n",
        "x = BatchNormalization(name='bn8')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(512, (3, 3), padding='same', name='conv9')(x)\n",
        "x = BatchNormalization(name='bn9')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(512, (3, 3), padding='same', name='conv10')(x)\n",
        "x = BatchNormalization(name='bn10')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "x = Conv2D(512, (3, 3), padding='same', name='conv11')(x)\n",
        "x = BatchNormalization(name='bn11')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(512, (3, 3), padding='same', name='conv12')(x)\n",
        "x = BatchNormalization(name='bn12')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(512, (3, 3), padding='same', name='conv13')(x)\n",
        "x = BatchNormalization(name='bn13')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "\n",
        "x = Dense(1024, activation = 'relu', name='fc1')(x)\n",
        "x = Dense(1024, activation = 'relu', name='fc2')(x)\n",
        "# Decoding Layer \n",
        "x = UpSampling2D()(x)\n",
        "x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv1')(x)\n",
        "x = BatchNormalization(name='bn14')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv2')(x)\n",
        "x = BatchNormalization(name='bn15')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv3')(x)\n",
        "x = BatchNormalization(name='bn16')(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D()(x)\n",
        "x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv4')(x)\n",
        "x = BatchNormalization(name='bn17')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv5')(x)\n",
        "x = BatchNormalization(name='bn18')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv6')(x)\n",
        "x = BatchNormalization(name='bn19')(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D()(x)\n",
        "x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv7')(x)\n",
        "x = BatchNormalization(name='bn20')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv8')(x)\n",
        "x = BatchNormalization(name='bn21')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv9')(x)\n",
        "x = BatchNormalization(name='bn22')(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D()(x)\n",
        "x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv10')(x)\n",
        "x = BatchNormalization(name='bn23')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv11')(x)\n",
        "x = BatchNormalization(name='bn24')(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D()(x)\n",
        "x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv12')(x)\n",
        "x = BatchNormalization(name='bn25')(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\n",
        "x = BatchNormalization(name='bn26')(x)\n",
        "x = Activation('sigmoid')(x)\n",
        "pred = Reshape((IMG_HEIGHT, IMG_WIDTH))(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cSYl9bXyesf"
      },
      "source": [
        "# Plotting Training Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdzTVlGnqyyY"
      },
      "source": [
        "plt.rcParams.update({'font.size': 20})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvL5optgAUIt"
      },
      "source": [
        "# After 200 epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fI_F3j2ASMo"
      },
      "source": [
        "model, hist = segnet(epochs_num= 200, savename= '/content/drive/MyDrive/Mestrado/Segmentation/Model/segnet_model_50_50_novo.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btFxxRkLBOC_"
      },
      "source": [
        "import pandas as p\n",
        "hist_df = pd.DataFrame(hist.history)\n",
        "hist_csv_file = '/content/drive/MyDrive/Mestrado/Segmentation/History/history_segnet_50_50_novo.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk5lyOqKBPms"
      },
      "source": [
        "model_3 = Model(inputs=img_input, outputs=pred)\n",
        "model_3.compile(optimizer= SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False), loss= [\"binary_crossentropy\"]\n",
        "              , metrics=[iou, dice_coef, precision, recall, accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sudlwEzSSiK7"
      },
      "source": [
        "model_3.load_weights('/content/drive/MyDrive/Mestrado/Segmentation/Model/segnet_model_30_70.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfhP8ALfJeJ1"
      },
      "source": [
        "# Plotting Training Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnPh-rcNSz-t"
      },
      "source": [
        "plt.figure(figsize=(20, 14))\n",
        "plt.suptitle('Training Statistics on Train Set')\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(hist.history['loss'], 'red')\n",
        "plt.title('Loss')\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(hist.history['accuracy'], 'blue')\n",
        "plt.title('Accuracy')\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(hist.history['val_loss'], 'red')\n",
        "plt.yticks(list(np.arange(0.0, 1.0, 0.10)))\n",
        "plt.title('Validation Loss')\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(hist.history['val_accuracy'], 'blue')\n",
        "plt.yticks(list(np.arange(0.0, 1.0, 0.10)))\n",
        "plt.title('Validation Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13e0_MkWS7wD"
      },
      "source": [
        "plt.figure(figsize=(20, 14))\n",
        "plt.suptitle('Training Statistics on Train Set')\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(hist.history['loss'], 'red')\n",
        "plt.title('Loss')\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(hist.history['iou'], 'blue')\n",
        "plt.title('IoU')\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(hist.history['val_loss'], 'red')\n",
        "plt.yticks(list(np.arange(0.0, 1.0, 0.10)))\n",
        "plt.title('Validation Loss')\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(hist.history['val_iou'], 'blue')\n",
        "plt.yticks(list(np.arange(0.0, 1.0, 0.10)))\n",
        "plt.title('Validation IoU')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOaHlzI3Jg5O"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL5dOApITMLD"
      },
      "source": [
        "print('\\n~~~~~~~~~~~~~~~Stats after 200 epoch~~~~~~~~~~~~~~~~~~~')\n",
        "print('\\n-------------On Train Set--------------------------\\n')\n",
        "res = model_3.evaluate(x_train, y_train, batch_size= 8)\n",
        "print('________________________')\n",
        "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
        "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
        "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
        "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
        "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
        "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
        "print('________________________')\n",
        "print('\\n-------------On Test  Set--------------------------\\n')\n",
        "res = model_3.evaluate(X_test, Y_test, batch_size= 8)\n",
        "print('________________________')\n",
        "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
        "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
        "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
        "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
        "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
        "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
        "print('________________________')\n",
        "print('\\n-------------On validation Set---------------------\\n')\n",
        "res = model_3.evaluate(x_val, y_val, batch_size= 8)\n",
        "print('________________________')\n",
        "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
        "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
        "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
        "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
        "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
        "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
        "print('________________________')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js9WIQ01Jkkm"
      },
      "source": [
        "# Visualising Predicted Lesions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdzJN67X37Mi"
      },
      "source": [
        "def enhance(img):\n",
        "    sub = (model_3.predict(img.reshape(1,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))).flatten()\n",
        "\n",
        "    for i in range(len(sub)):\n",
        "        if sub[i] > 0.5:\n",
        "            sub[i] = 1\n",
        "        else:\n",
        "            sub[i] = 0\n",
        "    return sub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2kCLIIlRYVK"
      },
      "source": [
        "ix = 0\n",
        "predicted = enhance(X_test[ix]).reshape(IMG_HEIGHT, IMG_WIDTH)\n",
        "\n",
        "visualize_01(\n",
        "    image=X_test[ix], \n",
        "    mask=np.squeeze(Y_test[ix]),\n",
        "    prediction=predicted\n",
        ")\n",
        "\n",
        "visualize(\n",
        "    image=X_test[ix], \n",
        ")\n",
        "\n",
        "visualize(\n",
        "    mask=np.squeeze(Y_test[ix]),\n",
        ")\n",
        "\n",
        "visualize(\n",
        "    prediction=predicted,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}