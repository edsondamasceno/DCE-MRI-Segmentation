{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "UNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tErBNi1A0J1o"
      },
      "source": [
        "# U-Net Segmentation\n",
        "\n",
        "Link: https://www.kaggle.com/marwa96/u-net-segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt7sRzzt1Au3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OLr03Fj1oPu"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "# importing required modules \n",
        "from zipfile import ZipFile \n",
        "\n",
        "from skimage.io import imread,imshow\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.ndimage.morphology import distance_transform_edt, binary_erosion, \\\n",
        "    generate_binary_structure\n",
        "from scipy.ndimage.measurements import label, find_objects\n",
        "\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgya2sRp1tKV"
      },
      "source": [
        "IMG_WIDTH = 320\n",
        "IMG_HEIGHT = 160\n",
        "IMG_CHANNELS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkB71R0Zqzrb"
      },
      "source": [
        "#Function for data visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVt2v1evqrSB"
      },
      "source": [
        "def visualize(**images):\n",
        "    \"\"\"PLot images in one row.\"\"\"\n",
        "    n = len(images)\n",
        "    plt.figure()\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXHQQfL10_K1"
      },
      "source": [
        "def visualize_01(**images):\n",
        "    \"\"\"PLot images in one row.\"\"\"\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHNqa1UKnmct"
      },
      "source": [
        "# Jaccard index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKbQKC8WnmDQ"
      },
      "source": [
        "def iou(y_true, y_pred, smooth = 100):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return jac"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rIurkwfntbG"
      },
      "source": [
        "# Dice coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlO3-s2fns_y"
      },
      "source": [
        "def dice_coef(y_true, y_pred, smooth = 100):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECc7vhkEnzSZ"
      },
      "source": [
        "# Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdQRJklCns2z"
      },
      "source": [
        "def precision(y_true, y_pred):\n",
        "    '''Calculates the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    '''\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvpJ8-DVn42E"
      },
      "source": [
        "# Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGrcEfd4nshO"
      },
      "source": [
        "def recall(y_true, y_pred):\n",
        "    '''Calculates the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    '''\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsRzkEEPn-EG"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdyIsvKAnsOR"
      },
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    '''Calculates the mean accuracy rate across all predictions for binary\n",
        "    classification problems.\n",
        "    '''\n",
        "    return K.mean(K.equal(y_true, K.round(y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE0jseMcq5Z0"
      },
      "source": [
        "#Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15gHcvRa103T"
      },
      "source": [
        "#Build the model\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "#Contraction path\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        " \n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        " \n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        " \n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "#Expansive path \n",
        "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        " \n",
        "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        " \n",
        "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        " \n",
        "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        " \n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        " \n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[iou, dice_coef, precision, recall, accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXC_O5eo17-J"
      },
      "source": [
        "# specifying the zip file name\n",
        "TRAIN_Name='/content/drive/MyDrive/Mestrado/Segmentation/DCE-MRI-50-50/dce-mri_train.zip'\n",
        "TEST_Name ='/content/drive/MyDrive/Mestrado/Segmentation/DCE-MRI-50-50/dce-mri_test.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfP2dHDlZ1Ra"
      },
      "source": [
        "with ZipFile(TRAIN_Name, 'r') as zip: \n",
        "    # printing all the contents of the zip file       \n",
        "    # extracting all the files \n",
        "    print('Extracting all the train files now...') \n",
        "    zip.extractall(\"stage_train\") \n",
        "    print('Done!') \n",
        "    \n",
        "# opening the test zip file in READ mode \n",
        "with ZipFile(TEST_Name, 'r') as zip: \n",
        "    # printing all the contents of the zip file     \n",
        "    # extracting all the files \n",
        "    print('Extracting all the test files now...') \n",
        "    zip.extractall(\"stage_test\") \n",
        "    print('Done!') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6HVmB-t62q5"
      },
      "source": [
        "TRAIN_PATH='/content/stage_train/dce-mri_train/'\n",
        "TEST_PATH='/content/stage_test/dce-mri_test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-STr8q2zaJ6Y"
      },
      "source": [
        "train_ids=next(os.walk(TRAIN_PATH))[1]\n",
        "test_ids=next(os.walk(TEST_PATH))[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fatRABWa9y8"
      },
      "source": [
        "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-LFZ40nmejt"
      },
      "source": [
        "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "Y_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjcdXx-6bBdK"
      },
      "source": [
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'Y_train shape: {Y_train.shape}')\n",
        "print(f'X_test shape: {X_test.shape}')\n",
        "print(f'Y_test shape: {Y_test.shape}')\n",
        "print(f'train_ids : {len(train_ids)}')\n",
        "print(f'test_ids : {len(test_ids)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4j0rvyR0ZI4"
      },
      "source": [
        "print('Resizing training images and masks')\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n",
        "    path = TRAIN_PATH + id_\n",
        "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]  \n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_train[n] = img  #Fill empty X_train with values from img\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "      \n",
        "        mask_ = imread(path + '/masks/' + mask_file)\n",
        "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
        "                                      preserve_range=True), axis=-1)\n",
        "        mask = np.maximum(mask, mask_)  \n",
        "            \n",
        "    Y_train[n] = mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Dty788f50u7"
      },
      "source": [
        "# test images\n",
        "sizes_test = []\n",
        "\n",
        "print('Resizing test images') \n",
        "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "    path = TEST_PATH + id_\n",
        "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
        "    sizes_test.append([img.shape[0], img.shape[1]])\n",
        "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "    X_test[n] = img\n",
        "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "        mask_ = imread(path + '/masks/' + mask_file)\n",
        "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
        "                                      preserve_range=True), axis=-1)\n",
        "        mask = np.maximum(mask, mask_)\n",
        "\n",
        "    Y_test[n] = mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq2p8FCQl6Yx"
      },
      "source": [
        "#Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5YzxrgR6LQS"
      },
      "source": [
        "seed=42\n",
        "np.random.seed=seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdfVFrqF6Ofb"
      },
      "source": [
        "#Modelcheckpoint\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.h5', verbose=1, save_best_only=True)\n",
        "\n",
        "callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
        "        tf.keras.callbacks.TensorBoard(log_dir='logs')]\n",
        "\n",
        "history = model.fit(X_train, Y_train, validation_split=0.1, batch_size=8, epochs=200, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1tgKLc0XGPc"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Mestrado/Segmentation/Model/unet_200_epoch_30_70.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EleTgdjXtZqS"
      },
      "source": [
        "import pandas as p\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_csv_file = '/content/drive/MyDrive/Mestrado/Segmentation/History/history_unet_200_epoch_30_70.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8WNO-vNqJra"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "plt.rcParams.update({'font.size': 20})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWr6d-K_q-1S"
      },
      "source": [
        "plt.figure(figsize=(20, 14))\n",
        "plt.suptitle('Training Statistics on Train Set')\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(history.history['loss'], 'red')\n",
        "plt.title('Loss')\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(history.history['accuracy'], 'blue')\n",
        "plt.title('Accuracy')\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(history.history['val_loss'], 'red')\n",
        "plt.yticks(list(np.arange(0.0, 1.0, 0.10)))\n",
        "plt.title('Valdiation Loss')\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(history.history['val_accuracy'], 'blue')\n",
        "plt.yticks(list(np.arange(0.0, 1.0, 0.10)))\n",
        "plt.title('Validation Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrcovlJtzIiq"
      },
      "source": [
        "plt.figure(figsize=(20, 14))\n",
        "plt.suptitle('Training Statistics on Train Set')\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(history.history['loss'], 'red')\n",
        "plt.title('Loss')\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(history.history['iou'], 'blue')\n",
        "plt.yticks(list(np.arange(0.999, 1.0, 0.0001)))\n",
        "plt.title('IoU')\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(history.history['val_loss'], 'red')\n",
        "plt.yticks(list(np.arange(0.0, 1.0, 0.10)))\n",
        "plt.title('Valdiation Loss')\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(history.history['val_iou'], 'blue')\n",
        "plt.yticks(list(np.arange(0.999, 1.0, 0.0001)))\n",
        "plt.title('Validation IoU')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKbwDAv7xByC"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLCMdqvf0NKO"
      },
      "source": [
        "model_1 = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=[iou, dice_coef, precision, recall, accuracy])\n",
        "\n",
        "model_1.load_weights('/content/drive/MyDrive/Mestrado/Segmentation/Model/unet_200_epoch_50_50.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLnCl9Nnqpo4"
      },
      "source": [
        "preds_train = model_1.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
        "preds_val = model_1.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
        "\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpzr3jyHqz8f"
      },
      "source": [
        "# Realize uma verificação de sanidade em algumas amostras de treinamento aleatórias\n",
        "ix = random.randint(0, len(preds_train_t))\n",
        "print('Imagem Numero: ', ix)\n",
        "\n",
        "imshow(X_train[ix])\n",
        "plt.show()\n",
        "\n",
        "#imshow(np.bitwise_xor(Y_train[ix]))\n",
        "#plt.show()\n",
        "\n",
        "#imshow(np.squeeze(preds_train_t[ix]))\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRKxivMfvsz7"
      },
      "source": [
        "# Realize uma verificação de sanidade em algumas amostras de validação aleatórias\n",
        "ix = random.randint(0, len(preds_val_t))\n",
        "print('Imagem Numero: ', ix)\n",
        "\n",
        "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
        "plt.show()\n",
        "\n",
        "#imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
        "#plt.show()\n",
        "\n",
        "#imshow(np.squeeze(preds_val_t[ix]))\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUEZ9EAGP5r8"
      },
      "source": [
        "print('\\n~~~~~~~~~~~~~~~Stats after 100 epoch~~~~~~~~~~~~~~~~~~~')\n",
        "print('\\n-------------On Train Set--------------------------\\n')\n",
        "res = model_1.evaluate(X_train, Y_train, batch_size= 8)\n",
        "print('________________________')\n",
        "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
        "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
        "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
        "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
        "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
        "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
        "print('________________________')\n",
        "print('\\n-------------On Test  Set--------------------------\\n')\n",
        "res = model_1.evaluate(X_test, Y_test, batch_size= 8)\n",
        "print('________________________')\n",
        "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
        "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
        "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
        "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
        "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
        "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
        "print('________________________')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPpXEX_cF4Tq"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXxQIOaTF3e4"
      },
      "source": [
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww2cjhO7Gpte"
      },
      "source": [
        "# Realize a predição no conjunto de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCVxf-nmGI_n"
      },
      "source": [
        "ix = 0\n",
        "\n",
        "visualize(\n",
        "    image=X_test[ix], \n",
        ")\n",
        "\n",
        "visualize(\n",
        "    mask=np.squeeze(Y_test[ix]),\n",
        ")\n",
        "\n",
        "visualize(\n",
        "    prediction=np.squeeze(preds_test_t[ix]),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ix = 0\n",
        "print('Imagem Numero: ', ix)\n",
        "\n",
        "visualize_01(\n",
        "    image=X_test[ix], \n",
        "    mask=np.squeeze(Y_test[ix]),\n",
        "    prediction=np.squeeze(preds_test_t[ix]),\n",
        ")"
      ],
      "metadata": {
        "id": "9xzprPSAF0f-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}